# -*- mode:org; -*-

#+title:Implementing SSL TLS Using Cryptography and PKI
#+subtitle:{{{version}}} {{{date}}}
#+author:LOLH
#+date:2020-11-23 21:32
#+macro:version Version 0.0.7
#+macro:upload-date (eval (current-time-string))
#+bucket:pinecone-forest.com

{{{version}}} {{{date}}}

#+texinfo:@insertcopying


* About
  :PROPERTIES:
  :unnumbered: yes
  :END:
#+texinfo: @heading Implementing SSL / TLS Using Cryptography and PKI
#+texinfo: @subheading by Joshua Davies
#+texinfo: @subsubheading ISBN: 978-0-470-92041-1

#+texinfo: @heading DESCRIPTION
Hands-on, practical  guide to implementing  SSL and TLS protocols  for Internet
security  If you  are  a network  professional who  knows  C programming,  this
practical book  is for  you. Focused  on how to  implement Secure  Socket Layer
(SSL) and  Transport Layer  Security (TLS),  this book  guides you  through all
necessary steps, whether  or not you have a working  knowledge of cryptography.
The book covers  SSLv2, TLS 1.0, and TLS 1.2,  including implementations of the
relevant   cryptographic  protocols,   secure  hashing,   certificate  parsing,
certificate generation, and more.

#+texinfo: @subheading Coverage includes:

- Understanding Internet Security
- Protecting against Eavesdroppers with Symmetric Cryptography
- Secure Key Exchange over an Insecure Medium with Public Key Cryptography
- Authenticating Communications Using Digital Signatures
- Creating a Network of Trust Using X.509 Certificates
- A Usable, Secure Communications Protocol: Client-Side TLS
- Adding Server-Side TLS 1.0 Support
- Advanced SSL Topics
- Adding TLS 1.2 Support to Your TLS Library
- Other Applications of SSL
- A Binary Representation of Integers: A Primer
- Installing TCPDump and OpenSSL
- Understanding the Pitfalls of SSLv2


Set up and launch a working implementation of SSL with this practical guide.

- Introduction xxvii
- Chapter 1 Understanding Internet Security 1
- Chapter 2 Protecting Against Eavesdroppers with Symmetric Cryptography 29
- Chapter 3 Secure Key Exchange over an Insecure Medium with Public Key Cryptography 91
- Chapter 4 Authenticating Communications Using Digital Signatures 157
- Chapter 5 Creating a Network of Trust Using X.509 Certifi cates 221
- Chapter 6 A Usable, Secure Communications Protocol: Client-Side TLS 297
- Chapter 7 Adding Server-Side TLS 1.0 Support 381
- Chapter 8 Advanced SSL Topics 415
- Chapter 9 Adding TLS 1.2 Support to Your TLS Library 479
- Chapter 10 Other Applications of SSL 543
- Appendix A Binary Representation of Integers: A Primer 567
- Appendix B Installing TCPDump and OpenSSL 573
- Appendix C Understanding the Pitfalls of SSLv2 579
- Index 629

* Introduction
:PROPERTIES:
:unnumbered: t
:END:
The  book  examines the  /Secure  Sockets  Layer/  (SSL) and  /Transport  Layer
Security/ (TLS) protocols in detail, taking a bottom-up approach.

#+cindex:SSL
- SSL :: standardized, widely  implemented, peer-reviewed protocol for applying
  cryptographic primitives to arbitrary networked communications. It provides:
  - privacy,
  - integrity,
  - some measure of authenticity
  - to otherwise inherently untrustworthy network connections.


This book develops, incrementally, a relatively complete SSL/TLS library.

- First, all of the relevant cryptographic protocols are examined and
  developed;
- Then, the library itself is built piece by piece.


All of the code developed in this book is C (not C++) code.

All of the protocols  and examples are presented in general form  as well as in
source code form  so that if you're interested in  a higher-level overview, you
can skip the code examples and the book should still make sense.

#+texinfo: @heading Why Source Code is Partially Incomplete

Effectively,  production-grade libraries  have at  least five  primary concerns
regarding their source code:

1. It must work

2. It must be secure

3. It should be as fast as reasonably possible

4. It must be modular and extensible

5. It must be easy to read and understand


When a  higher-numbered concern  conflicts with  a lower-numbered  concern, the
lower-numbered concern  wins. This must  be the  case for cade  that's actually
used by real people  to perform real tasks. The code is  not always pretty, nor
is it particularly readable, when security-speed-modularity take precedence.

The priorities for the code in this book are:

1. It must work

2. It should be as readable as possible.


Security, speed  and modularity are  not concerns.  The code presented  in this
book is  /not/ particularly secure. For  example, when the algorithms  call for
random bytes, the  code in this book just returns  sequentially numbered bytes,
which is the exact  opposite of the random bytes that  the algorithm calls for.
This is done to simplify the code as well  as to make sure that what you see if
you try it out yourself matches what you see in the book.

There  isn't any  bounds-checking on  buffers  or verification  that the  input
matches what's  expected, which are  things that a  proper library ought  to be
doing. I've omitted  these things to keep this book's  page count under control
as well as to avoid obscuring the  purpose of the example code with hundreds of
lines of error checking.

If  you   are  working   with  any   production  code   you  should   prefer  a
well-established library such  as OpenSSL, GnuTLS, or NSS  over home-grown code
any day. This book should help  you understand the internals of these libraries
so that, when it comes time to use one, you know exactly what's going on at all
stages.

** Supplemental Web Sites

#+cindex:Request for Comment
#+cindex:RFC
#+cindex:IETF
#+cindex:Internet Engineering Task Force
To see the source /Request for Comment/ documents (RFCs), visit the /Internet
Engineering Task Force/ (IETF) web site at:

- https:www.ietf.org


Each RFC is stored in a document under:
: https://www.ietf.org/rfc/rfc<dddd>.txt
where <dddd> is the RFC number, e.g.,

https://www.ietf.org/rfc/rfc2246.txt

for example.

See also:

- International Telecommunication Union (ITU) "X series" documents

  - https://www.itu.int/rec/T-REC-X/en

- RSA laboratories' /Public Key Cryptography Standards/ (PKCS)
  - https://www.rsa.com/rsalabs/node.asp?id=2124

  - https://tools.ietf.org/html/rfc3447#page-70


All of the standards documents referenced in this book are freely available and
downloadable. I  try to explain  the background information that  the standards
documents  always seem  to take  for granted.  I am  assuming that  if you  are
interested  in the  low-level  detail you  can always  refer  to the  standards
document itself.

** Companion Source Code

- https://www.wiley.com/go/implementingssl
- https://www.wiley.com/en-us/Implementing+SSL+TLS+Using+Cryptography+and+PKI-p-9780470920411

** How to Read This Book
This book is written to be read cover  to cover. If you have some background in
C programming,  you will  want to  read through  and compile  and run  the code
samples. The benefit  of the code samples  is that it's impossible  to omit any
detail---accidentally  or  intentionally---when writing  code,  so  if you  can
understand the  code, it will cement  your understanding of the  text preceding
it.

Although this is a book about SSL/TLS, the first half of the book just sets the
stage for  SSL/TLS by presenting all  of the protocols and  standards they rely
on.

My  primary motivation  in writing  this book  was to  present, in  detail, the
interplay between the SSL and TLS protocols and the cryptographic routines that
they rely upon.

** Errata
|---------+------+-----------------------------------------------------------------------------------------------------------------------------------|
| Chapter | Page | Details                                                                                                                           |
|---------+------+-----------------------------------------------------------------------------------------------------------------------------------|
|         |   29 | Error in Text: "GET" should be the letters G, E, and T followed by a space.                                                       |
|         |      | This is referring to a specific character sequence.                                                                               |
|         |   71 | Error in Text: Third paragraph, second sentence:                                                                                  |
|         |      | "If you multiply this with any other (four-column) matrix"                                                                        |
|         |      | should read:                                                                                                                      |
|         |      | "If you multiply this with any other (four row) matrix"                                                                           |
|         |      | ALSO The lowest matrix, on the left-hand, should show a ^-1 inversion  notation                                                   |
|         |   90 | Error in Text: Last paragraph, last sentence should read:                                                                         |
|         |      | "CTR mode didn't make it into TLS..."                                                                                             |
|         |  100 | Error in Text: At the bottom, should read:                                                                                        |
|         |      | "49200 + 6150 + 738 = 56088"                                                                                                      |
|         |  129 | Error in Text: the "Procedure for generating RSA keypairs" sidebar states:                                                        |
|         |      | 3. Compute the totient function (p-1)(1-1)                                                                                        |
|         |      | This should read:                                                                                                                 |
|         |      | 3. Compute the totient function (p-1)(q-1)                                                                                        |
|         |  130 | Error in Text                                                                                                                     |
|         |      | Reads: "its slow runtime limits is practical uses".                                                                               |
|         |      | Should read: "its slow runtime limits its practical uses".                                                                        |
|         |  133 | Error in Text: Reads: "sqrt(x^3-ax) has no solutions between 0 and 1 because x^3 - ax < 0".                                       |
|         |      | Should read: "sqrt(x^3-x) has no solutions between 0 and 1 because x^3 - x < 0".                                                  |
|         |  155 | Error in Text: Text states:                                                                                                       |
|         |      | "OpenSSL 1.0, although it includes elliptic-curve operations, doesn't support TLS 1.2, and therefore doesn't support online ECC". |
|         |      | Actually, as of February 8, 2011, while openssl 0.9.8r does not support elliptic-curve ciphersuites, openssl 1.0.0 does.          |
|         |  160 | Error in Text: Text states:                                                                                                       |
|         |      | "Obviously, with such a 4:1 ratio of input blocks to output blocks, there will be at least a one in four chance of a collision."  |
|         |      | Actually, over the entire input space, the chance of a collision is actually significantly smaller than 1 in 4.                   |
|---------+------+-----------------------------------------------------------------------------------------------------------------------------------|

* Understanding Internet Security
How secure is the date that you transmit on the Internet?  How vulnerable is
your personal data to hackers?

- standard encryption algorithms
- public-key algorithms
  - RSA
  - DSA
- Data Encryption Standard -> Advanced Encryption Standard
- HTTPS -> browser security
- PGP -> email security
- man in the middle attacks
- timing attacks
- side-channel attacks
- certificates -> expired, untrusted CA
- zero-day exploit
- IETF
- PKCS
- FIPS
- NIST
- ITU
- ASN
- RFC 2246 -> TLS
- symmetric cryptography
- public-key cryptography
- digital signature algorithms
- X.509 certificates


As a practitioner rather than a casual  user, it's not enough to treat security
as a  black box or  a binary property;  you need to  know what the  security is
doing and how it's doing it so that  you know what you are and aren't protected
against.  This book was written for you---the professional programmer who
understands the basics of security but wants to uncover the details without
reading thousands of pages of specifications.

This book begins by examining *sockets* and *socket programming* in brief.

Afterward, it moves on to a detailed examination of *cryptographic concepts*.

and finally applies thenm to *SSL/TLS*.

You examine what SSL/TLS does, what it doesn't do, and how it does it.

** What are Secure Sockets?
#+cindex:packet-switching network
The Internet is a /packet-switching/ network.

#+cindex:packetize data
#+cindex:data, packets
#+cindex:router
#+cindex:destination address
This means that, for two hosts to communicate, they must /packetize/ their data
and  submit it  to a  router  with the  destination address  prepended to  each
packet. The router then analyzes the  destination address and routes the packet
either to  the target host, or  to a router that  it believes is closer  to the
target host.

#+cindex:Internet Protocol
#+cindex:IP
#+cindex:RFC 971, packetization
#+cindex:packetization RFC 971
The /Internet Protocol/ (IP), outlined in ([[https://www.ietf.org/rfc/rfc791.txt][RFC 791]]), describes the standard for
how this packetization  is performed and how addresses are  attached to packets
in headers.

A packet can and probably will pass through many routers between the sender and
the receiver.  If the contents  of the data in  that packet are  sensitive, the
sender  would probably  like to  ensure  that only  the receiver  can read  the
packet, rather than the packet being readable by any router along the way.

#+cindex:attacker
#+cindex:spoofing, dns
#+cindex:dns spoofing
Even  if the  sender trusts  the routers  and their  operators, routers  can be
compromised   by  malicious   individuals,  called   /attackers/  in   security
terminology,  and  tricked  into  forwarding   traffic  that's  meant  for  one
destination to another, as shown in
- http://www.securesphere.net/download/papers/dnsspoof.htm
- https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1004.5649&rep=rep1&type=pdf
- https://www.imperva.com/learn/application-security/dns-spoofing/
- https://www.giac.org/paper/gcih/364/dns-spoofing-attack/103863


#+cindex:traceroute
#+cindex:hops
To get an idea how many different  hosts a packet passes through betwen you and
a  server,  you  can  use  the ~traceroute~  facility  that  comes  with  every
Internet-capable  computer to  print a  list of  the hops  between you  and any
server on the Internet.

: $ traceroute www.travelocity.com

#+cindex:ICMP timeout packet
#+cindex:Transport Control Protocol RFC 793
#+cindex:RFC 793 TCP
Each router along the  way is supposed to respond with  a special packet called
an ICMP  timeout packet,  as described in  [[https://www.ietf.org/rfc/rfc793.txt][RFC 793]], with  its own  address. The
routers that cannot or will not do so are represented with =* * *=.

#+cindex:socket, definition
#+cindex:synchronize (SYN) packet
#+cindex:SYN (synchronize) packet
In network programming parlance, the tenuous  connection between a sender and a
receiver is referred  to as a /socket/.  When one host --- the  /client/ --- is
ready to establish  a connection with another  --- the /server/ ---  it sends a
/synchronize/ (=SYN=) packet to the server.  If the server is willing to accept
the connection, it responds with  a /synchronize/ and /acknowledge/ (=SYN/ACK=)
packet. Finally, the client acknowledges the acknowledgment and both sides have
agreed on a connection.

#+cindex:TCP handshake
#+cindex:handshake, TCP
This three-packet exchange is referred to as the /TCP handshake/.

#+cindex:source port
#+cindex:destination port
The connection is associated with a pair  of numbers: the /source port/ and the
/destination  port/,  which are  attached  to  each  subsequent packet  in  the
communication.

#+cindex:TCP RFC 793
#+cindex:Transport Control Protocol RFC 793
Because the server is sitting around, always listening for connections, it must
advertise  its   destination  port  ahead  of   time.  How  this  is   done  is
protocol-specific.  Some protocols  are lucky  enough to  have "magic  numbers"
associated with  them that are well-known  (you the programmer are  supposed to
know them). This  is the /Transport Control Protocol/ (TCP);  [[https://www.ietf.org/rfc/rfc793.txt][RFC 793]] describes
exactly how  this works and  how both sides agree  on a source  and destination
port and how they sequence these and subsequent packets.

#+cindex:sock
TCP  and IP  are usually  implemented together  and called  TCP/IP. A  /socket/
refers to an established TCP connection;  both sides, client and server, have a
socket  after  the three-way  handshake  has  been  completed. If  either  side
transmits data  over this socket, TCP  guarantees, to the best  of its ability,
that the other side sees this data in  the order it was sent. As is required by
IP, any intermediate router along the way also sees this data.

#+cindex:SSL
#+cindex:Secure Sockets Layer
/SSL/  stands  for /Secure  Sockets  Layer/  and  was originally  developed  by
Netscape as a way to allow the browser technology to be used for e-commerce. It
has since been standardized and renamed /Transport Layer Security/ (TLS). After
a socket has been established between the  client and the server, SSL defines a
second handshake that  can be performed to establish a  secure channel over the
inherently insecure TCP layer.

** "Insecure" Communications---Understanding the HTTP Protocol
#+cindex:HTTP
#+cindex:Hypertext Transport Protocol
#+cindex:RFC 2616, HTTP
#+cindex:web clients, browsers
#+cindex:web servers
/HTTP/, or /Hypertext Transport Protocol/, officially described in [[https://www.ietf.org/rfc/rfc2616.txt][RFC 2616]], is
the standard protocol for web communication.  Web clients ("browsers")
establish sockets with web servers.  HTTP uses the established port 80.

After the  socket has been  established, the  web browser begins  following the
rules set forth by the HTTP protocol  to request documents. HTTP started out as
a fairly simple protocol. Over the years, HTTP has been refined quite a bit and
optimized for bandwidth, speed, and security features.

#+cindex:SSL from HTTP
#+cindex:HTTPS
HTTP was  also the primary motivator  for SSL. Originally, SSL  didn't stand on
its own; it was  designed as an add-on to HTTP, called  HTTPS. Although SSL was
subsequently decoupled from HTTP, some of its features were optimized for HTTP,
leaving it to be a bit of a square peg in a round hole in some other contexts.

#+cindex:HTTP client, develop
Because  HTTP and  SSL go  so well  together, in  this book  I motivate  SSL by
developing an  HTTP client  and adding security  features to  it incrementally,
finally arriving at a working HTTP/SSL implementation.

** Implementing an Insecure HTTP Client

 #+cindex:HTTP client, implementing
 Web browsers  are complex because they  need to parse and  render HTML---and in
 most cases, render  images, run Javascript, Flash, Java Applets  and leave room
 for new, as-yet-uninvented add-ons.

 #+cindex:wget utility
 However, a web client that only retrieves a document from a server, such as the
 ~wget~ utility  that comes standard  with most Unix distributions,  is actually
 pretty   simple.  Most   of  the   complexity   is  in   the  socket   handling
 itself---establishing the socket and sending and receiving data over it.

*** Steps in Implementing an Insecure HTTP Client
    :PROPERTIES:
    :header-args: :noweb-ref insecure_http.c
    :END:
**** Implementing the HTTP Client Header---Includes---Defines

 Start with all  of the ~#include~'s  and ~#define~'s that go  along with socket
 communication, shown in Listing 1-1.

 #+caption:"http.c" header #includes and #defines
 #+name:http.c-header-includes
 #+begin_src c
   /**
   ,*  This test utility does simple (non-encrypted) HTTP
   ,*/

   #include <stdio.h>
   #include <stdlib.h>
   #include <errno.h>
   #include <string.h>
   #include <sys/types.h>
   #include <netdb.h>
   #include <sys/socket.h>
   #include <netinet/in.h>
   #include <unistd.h>

   #define HTTP_PORT        80
   #define BUFFER_SIZE     255
   #define MAX_GET_COMMAND 255

 #+end_src

**** Implementing the HTTP Client Function =parse_url= 

 #+pindex:parse_url
 The main routine is invoked with a URL of the form
 : http://www.server.com/path/to/document.html
 You need to separate the host and the path using a utility routine ~parse_url~,
 shown in Listing 1-2.

 #+caption:"http.c" parse_url
 #+name:http.c-parse_url
 #+begin_src c
   /**
    ,* Accept a well-formed URL (e.g. http://www.company.com/index.html) and return
    ,* pointers to the host part and the path part. Note that this function
    ,* modifies the uri itself as well. It returns 0 on success, -1 if the URL is
    ,* found to be malformed in any way.
    ,*/

   int parse_url( char *uri, char **host, char **path )
   {
     char *pos;

     pos = strstr( uri, "//" );

     if ( !pos )
       {
	 return -1;
       }

     ,*host = pos + 2;

     pos = strchr( *host, '/' );

     if ( !pos )
       {
	 ,*path = NULL;
       }
     else
       {
	 ,*pos = '\0';
	 ,*path = pos + 1;
       }

     return 0;
   }

 #+end_src

 You scan through the URL, looking for the delimiters =//= and =/= and replace
 them with null-terminators so that the caller can treat them as C strings.  The
 calling function passes in two pointers to pointers; these should be null when
 the function starts and will be modified to point into the =uri= string, which
 came from ~argv~.

**** Implementing An HTTP GET Command Function

 An HTTP =GET= command is a simple,  plaintext command. It starts with the three
 ASCII-encoded letters  =G E T=,  all in uppercase  (HTTP is case  sensitive), a
 space, the path to  the document to be retrieved, another  space, and the token
 =HTTP/1.0= OR  =HTTP/1.1= depending on which  version of the HTTP  protocol the
 client understands.[fn:1]

 The =GET= command itself is  followed by a carriage-return/line-feed pair (0x0A
 0x0D) and a colon-separated, CRLF-delimited list of /headers/ that describe how
 the client wants the response to be returned. Only one header is required---the
 =Host= header,  which is required  to support /virtual hosting/,  the situation
 where  severral hosts  share one  IP  address or  vice-versa. The  =Connection=
 header is not  required, but in general  you should send it to  indicate to the
 client whether  you want  it to  =Keep-Alive= the  connection---if you  plan on
 requesting more documents on this same  socket---or =Close= it. if you omit the
 =Connection: Close=  header line  the server  keeps the  socket open  until the
 client closes it.  If you're just sending a single request and getting bakc a
 single response, it's easier to let the server just close the connection when
 it's done sending.  The header list is teminated by an empty CRLF pair.

 A minimal HTTP =GET= command looks like this:

 : GET /index.html HTTP/1.1
 : Host: www.server.com
 : Connection: close

 The code  to format and  submit a =GET= command  over an established  socket is
 shown in Listing 1-6. Note that the input is the socket itself---the connection
 argument---the path of the document being requested, and the host (to build the
 host header).

 #+caption:"http.c" http_get
 #+name:http.c-http_get
 #+begin_src c
   /**
    ,* Format and send an HTTP get command. The return value will be 0 on
    ,* success, -1 on failure, with errno set appropriately. The caller
    ,* must then retrieve the response.
    ,*/

   int http_get( int connection, const char *path, const char *host )
   {
     static char get_command[ MAX_GET_COMMAND ];

     sprintf( get_command, "GET /%s HTTP/1.1\r\n", path );
     if ( send( connection, get_command, strlen( get_command ), 0 ) == -1 )
     {
       return -1;
     }

     sprintf( get_command, "Host: %s\r\n", host );
     if ( send( connection, get_command, strlen( get_command ), 0 ) == -1 )
     {
       return -1;
     }

     sprintf( get_command, "Connection: close\r\n\r\n" );
     if ( send( connection, get_command, strlen( get_command ), 0 ) == -1 )
     {
       return -1;
     }

     return 0;
   }

 #+end_src

**** Implementing a =display_result= Function

 Finally, output the response from the  server. To keep things simple, just dump
 the contents of the response on stdout. An HTTP response has a standard format,
 just like an  HTTP request. The response is the  token =HTTP/1.0= or =HTTP/1.1=
 depending on which  version the server understands (which  does not necessarily
 have to match the client's version), followed by a space, followed by a numeric
 code indicating the  status of the request---errored,  rejected, processed, and
 so on---followed by a textual, human-readable description of the meaning of the
 status code.

 Some of the more common status codes are shown in Table 1-1.

 #+caption:Common status codes
 #+name:common-http-response-status-codes
 |--------+-----------------------------------------------------------------------------|
 | Status | Meaning                                                                     |
 |--------+-----------------------------------------------------------------------------|
 |    200 | Everything was OK, requested document follows                               |
 |    302 | Requested document exists, but has been moved -- new location follows       |
 |    403 | Forbidden: requested document exists, but you are not authorized to view it |
 |    404 | Requested document not found                                                |
 |    500 | Internal server error                                                       |
 |--------+-----------------------------------------------------------------------------|

 Status codes are described in [[https://www.ietf.org/rfc/rfc2616.txt][RFC 2616]].

 The response status line is followed by a CRLF, and a series of
 colon-separated, CRLF delimited headers, a standalong CRL/blank line
 end-of-headers marker, and the document itself.

 For testing purposes, you don't care about the response itself, as long as you
 got one.  Therefore, don't make any efforts to parse these responses---just
 dump their contents, verbatim, on stdout, as shown in Listing 1-7.

 #+caption:"http.c" display_result
 #+name:http.c-display_result
 #+begin_src c
   /**
    ,* Receive all data available on a connection and dump it to stdout
    ,*/

   void display_result( int connection )
   {
     int received = 0;

     static char recv_buf[ BUFFER_SIZE + 1 ];

     while ( ( received = recv( connection, recv_buf, BUFFER_SIZE, 0 ) ) > 0 )
     {
       recv_buf[ received ] = '\0';
       printf( "%s", recv_buf );
     }

     printf( "\n" );
   }

 #+end_src

 This is all that's required to implement a bare-bones web client.  Note,
 however, that because the socket created was a cleartext socket, everything
 that's transmitted between the client and the server is observable, in
 plaintext, to every host in between.  In general, if you want to protect the
 transmission from eavesdroppers, you establish SSL context---that is, /secure
 the line/---prior to sending the =GET= command.

**** Implementing the Insecure HTTP Client =main= Function

 The main routine that coordinates all of this is shown in Listing 1-3.

 #+caption: "http.c" main
 #+name:http.c-main
 #+begin_src c
   /**
    ,*  Simple command-line HTTP client.
    ,*/

   int main( int argc, char *argv[ ] )
   {
     int client_connection;
     char *host, *path;
     struct hostent *host_name;
     struct sockaddr_in host_address;

     if ( argc < 2 )
       {
	 fprintf( stderr, "Usage: %s: <URL>\n", argv[ 0 ] );
	 return 1;
       }

     if ( parse_url( argv[ 1 ], &host, &path ) == -1 )
       {
	 fprintf( stderr, "Error - malformed URL '%s . \n", argv[ 1 ] );
	 return 1;
       }

     printf( "Conecting to host '%s'\n", host );

 #+end_src

 After the  URL has  been parsed  and the host  is known,  you must  establish a
 socket to it. In order to do  this, convert it from a human-readable host name,
 as =www.server.com=, to a dotted-decimal IP address, such as =100.218.64.2=.
 You call the standard ~gethostbyname~ library function to do this, and connect
 to the server.  This is shown in Listing 1-4.

 #+caption:"http.c" main (continued)
 #+name:http.c-main-continued
 #+begin_src c
   // Step 1: open a socket connection on http port with the destination host

     client_connection = socket( PF_INET, SOCK_STREAM, 0 );

     if ( !client_connection )
     {
       perror( "Unable to create a local socket" );
       return 2;
     }

     host_name = gethostbyname( host );

     if ( !host_name )
     {
       perror( "Error in name resolution" );
       return 3;
     }

     host_address.sin_family = AF_INET;
     host_address.sin_port = htons( HTTP_PORT );
     memcpy( &host_address.sin_addr, host_name->h_addr_list[ 0 ],
	   sizeof( struct in_addr ) );

     if ( connect( client_connection, ( struct sockaddr * ) &host_address,
	     sizeof( host_address ) ) == -1 )
     {
       perror( "Unable to connect to host" );
       return 4;
     }

     printf( "Retrieving document: '%s'\n", path );

 #+end_src

 Assuming nothing went wrong:

 - the socket structure could be created
 - the hostname could be resolved to an IP address
 - the IP address was reachable, and
 - the server accepted your connection on the well-known port 80


 You now have a  usable (cleartext) socket with which to  exchange data with the
 web server. Issue a =GET= command, display the result, and close the socket, as
 shown in Listing 1-5.

 #+caption:"http.c" main-continued-2
 #+name:http.c-main-continued-2
 #+begin_src c
   // Step 2: Issue a GET command

     http_get( client_connection, path, host );

     display_result( client_connection );

     printf( "Shutting down.\n" );

     if (close( client_connection ) == -1 )
     {
       perror( "Error closing client connection" );
       return 5;
     }

     return 0;
   }

 #+end_src

*** Code Listing for the Implementation of an Insecure HTTP Client

 This is the full code listing for the Insecure HTTP Client.

 #+header: :noweb yes
 #+header: :mkdirp yes
 #+header: :tangle resources/src/implementing-http-client/insecure-http-client/insecure_http.c
 #+begin_src c -n
 <<insecure_http.c>>
 #+end_src

*** Adding Support for HTTP Proxies
:PROPERTIES:
:header-args: :noweb-ref insecure_http.c-with_proxy
:END:
Notice that a socket  had to be created from the client to  the server before a
document could  be requested.   This means that  the client had  to be  able to
construct a  =SYN= packet, hand  that off  to a router,  which hands it  off to
another router, and  so on until its  received by the server.   The server then
constructs  its own  =SYN/ACK=  packet, hands  it  off, and  so  on until  it’s
received by the  client.  However, in corporate  intranet environments, packets
from  outside the  corporate domain  are not  allowed in,  and vice  versa.  In
effect, there is no route from the client  to the server with which it wants to
connect.

It’s typical to set up a /proxy  server/ that can connect to the outside world,
and have  the client funnel its  requests through the proxy.   This changes the
dynamics  a bit;  the client  establishes a  socket connection  with the  proxy
server first, and issues  a =GET= request to it.  After  the proxy examines the
request to determine  the host name, resolves the IP  address, connects to that
IP address on  behalf of the clinet, re-issues the  =GET= request, and forwards
the response  back to the  client.  This subtly  changes the dynamics  of HTTP.
What’s important  to notice is  that the client  establishes a socket  with the
proxy server, and the =GET= request now includes the full URL.

Because proxies present some unique challenges  for SSL, go ahead and add proxy
support to the minimal HTTP client developed in the preceding section.

**** Implementing Proxy Support in ~main~ 
You need to  modify the main routine to accept  an optional proxy specification
parameter.  A proxy  specification includes the /hostname/ of  the proxy server
itself, but it  also typically allows a /username/ and  /password/ to be passed
in, as most HTTP proxies are or can be authenticating.

   : http://[username:password@]hostname[:port]/

   where  =hostname= is  the  only part  that is  required.   Modify your  main
   routine to accept an optional proxy parameter, preceded by =-p=.


#+caption: “http.c” main with proxy support
#+name:http.c-main-proxy-1
#+begin_src c
  /**
   ,*  Simple command-line HTTP client with Proxy support
   ,*/

  int main( int argc, char *argv[ ] )
  {
    int client_connection;
    //---------------------------------------------
    char *proxy_host, *proxy_user, *proxy_password;
    int proxy_port;
    //---------------------------------------------
    char *host, *path;
    struct hostent *host_name;
    struct sockaddr_in host_address;
    //---------------------------------------------
    int ind;
    //---------------------------------------------

    if ( argc < 2 )
      {
	fprintf( stderr, "Usage: %s: <URL>\n", argv[ 0 ] );
	return 1;
      }

    if ( parse_url( argv[ 1 ], &host, &path ) == -1 )
      {
	//------------------------------------------------------------------------
	fprintf( stderr,
		 "Usage: %s: [-p http://[username:password*]proxy-host:proxy-port]\
  <URL>\n",
		 argv[ 0 ] );
	//------------------------------------------------------------------------
	return 1;
      }

    //------------------------------------------------------------------------
    proxy_host = proxy_user = proxy_password = host = path = NULL;
    ind = 1;
    if ( !strcmp( "-p", argv[ ind ] ) )
      {
	if ( !parse_proxy_param( argv[ ++ind ], &proxy_host, &proxy_port,
				 &proxy_user, &prox_password ) )
	  {
	    fprintf( stderr, "Error - malformed proxy parameter ’%s’.\n", argv[ 2 ] );
	    return 2;
	  }
	ind++;
      }
    if ( parse_url ( argv[ ind ], &host, &path ) == -1 )
    //------------------------------------------------------------------------
#+end_src

If the first argument is =-p=, take the second argument to be a proxy
specification in the canonical form and parse it.  Either way, the lst argument
is still a URL.

If  ~parse_proxy_param~ succeeds,  ~proxy_host~ is  a non-null  pointer to  the
host-name  of the  proxy  server.  You  need  to  maka a  few  changes to  your
connection logic  to support this  correctly.  First,  you need to  establish a
socket connection to the proxy host rather than the actual target HTTP host.

#+caption: “http.c” main with proxy support (continued)
#+name:http.c-main-proxy-2
#+begin_src c
  //------------------------------------------------------
    if ( proxy_host )
      {
	printf( "Connecting to host ’%s’\n", proxy_host );
	host_name = gethostbyname( proxy_host );
      }
    else
  //-------------------------------------------------------
      {
	printf( "Connecting to host ’%s’\n", host );
	host_name = gethostbyname( host );
      }
    host_address.sin_family = AF_INET;
    host_address.sin_port = htons( proxy_host ? proxy_port : HTTP_PORT );
    memcpy( &host_address.sin_addr, host_name->h_addr_list[ 0 ],
	  sizeof( struct in_addr) );

  /*...*/
  http_get( client_connection, path, host, proxy_host, proxy_user,
	    proxy_password );
#+end_src

Finally,  pass the  proxy  host, user,  and password  to  ~http_get~.  The  new
~parse_proxy_param~ function works similarly  to the ~parse_url~ function: pass
in a pointer  to the ~argv~ string,  insert nulls at strategic  places, and set
~char  *~ pointers  to  the  appropriate places  within  the  ~argv~ string  to
represent the individual pieces.

**** Implementing Insecure HTTP ~parse_proxy_param~ Code
#+caption: “http.c” parse_proxy_param
#+name:http.c-parse_proxy_param-1
#+begin_src c
  int parse_proxy_param( char *proxy_spec,
			 char **proxy_host,
			 int *proxy_port,
			 char **proxy_user,
			 char **proxy_password )
  {
    char *login_sep, *colon_sep, *trailer_sep;
    // Technically, the user should start the proxy spec with
    // “http://”. But, be forgiving if didn’t.
    if ( !strncmp( "http://", proxy_spec, 7 ) )
      {
	proxy_spec += 7;
      }
  }
#+end_src

Check to see  if an authentication string has been  supplied.  If the =@=symbol
appears in the ~proxy_spec~, it must be preceded by a =username:password= pair.
If it is, parse  those out; if it isn’t, there’s no  error because the username
and password are not strictly required.

#+caption: “http.” parse_proxy_param (continued)
#+name:http.c-parse_proxy_param-2
#+begin_src c
  //
    login_sep = strchr( proxy_spec, '@' );

    if ( login_sep )
    {
      colon_sep = strchr( proxy_spec, ':' );
      if ( !colon_sep || ( colon_sep > login_sep ) )
	{
	  // Error - if username supplied, password must be supplied
	  fprintf( stderr, "Expected password in ’%s’\n", proxy_spec );
	  return 0;
	}
      ,*colon_sep = '\0';
      ,*proxy_user = proxy_spec;
      ,*login_sep = '\0';
      ,*proxy_password = colon_sep + 1;
      proxy_spec = login_sep + 1;
    }
#+end_src

Notice  that,  if  a  username  and  password  are  supplied,  you  modify  the
~proxy_spec~ parameter  to point  to the  character after  the =@=.   This way,
~proxy_spec~ now points to the proxy  host whether an authentication string was
supplied or not.

Here is the  rest of the proxy  parameter parsing---the user can  supply a port
number if the proxy is listening on a non-standard port.

#+caption: “http.c” parse_proxy_param (continued 2)
#+name:http.c-parse_proxy_param-3
#+begin_src c
  // if the user added a “/” on the end
  // just ignore it
  trailer_set = strchr( proxy_spec, '/');
  if ( trailer_sep )
    {
      ,*trailer_sep = '\0';
    }

  colon_sep = strchr( proxy_spec, ':' );
  if (colon_sep )
    {
      // non-standard proxy port
      ,* colon_sep = '\0';
      ,*proxy_host = proxy_spec;
      ,*proxy_port = atoi( colon_sep + 1 );
      if ( *proxy_port == 0 )
	{
	  // 0 is not a valid port; this is an error; whether
	  // it was mistyped or specified as 0.
	  return 0;
	}
    }
   else
     {
       ,*proxy_port = HTTP_PORT;
       ,*proxy_host = proxy_spec;
     }
  return 1;
  }
#+end_src

The port number is also optional.  If there’s a =:= character before the end of
the proxy specification, it denotes a port; otherwise, assume the standard HTTP
port 80.

**** Implementing Insecure HTTP with Proxy Support---~http_get~ Routine
At this point  you have all the  pieces you need for HTTP  proxy support except
for the changes to the actual  ~http_get~ routine.  When connecting to a proxy,
you need  to send  a whole  hostname because  the socket  itself has  just been
established between the client and the proxy.  The request line becomes:
: GET http://host/path HTTP/1.0
Chage ~http_get~  as shown  to recognize  this case  and send  a proxy-friendly
=GET= command if a proxy host parameter has been supplied.

#+caption:http_get (modified for proxy support)
#+name:http_get-proxy
#+begin_src c
  int http_get( int connection,
		const char *path,
		const char *host,
		const char *proxy_host,
		const char *proxy_user,
		const char *proxy_password )
  {
    static char get_command[ MAX_GET_COMMAND ];
    if ( proxy_host )
      {
	sprintf( get_command, "GET http://%s/%s HTTP/1.1\r\n", host, path );
      }
    else
      {
	sprintf( get_command, "GET /%s HTTP/1.1 \r\n", path );
      }
  }
#+end_src

If the proxy is non-authenticating, this is all you need to do.  If the proxy
is an authenticating proxy, as most are, you need to supply an additional HTTP
header line including the proxy authorization string.
: Proxy-Authorization: [METHOD] [connection string]

=[METHOD]=, according to  RFC 2617, is one of =BASIC=,  or =DIGEST=.  It’s also
common to  see the non-standard  =NTLM= in Microsoft environments.   =BASIC= is
the simplest of  the three, and the  only one you will support.   The format of
/connection  string/ varies  depending on  the  =METHOD=.  For  =BASIC=, it  is
~base64_encode(’username:passord’).

*** Insecure HTTP with Proxy Support Full Listing
#+caption:Listing for Proxy Support
#+name:simple-http-with-proxy-support
#+header: :noweb yes
#+begin_src c
  <<insecure_http.c-with_proxy>>
#+end_src

* Build Tools
:PROPERTIES:
:appendix: t
:custom_id: build-tools
:END:
** Makefile					:dependencies:env_vars:perl:
:PROPERTIES:
:appendix: t
:dependency1: make
:dependency2.0: AWS User account at https://aws.amazon.com
:dependency2.1: AWS cli v2 in PATH https://docs.aws.amazon.com/cli/index.html
:dependency2.2: See how to Install AWS CLI v2 at https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-mac.html
:dependency2.3: aws credentials: access token and secret access token stored in ~/.aws/credentials
:dependency2.4: AWS S3 buckets set up for serving a static web page
:dependency3: GitHub Account with personal access token stored in GITHUB_TOKEN
:dependency4: texinfo @6.7._
:dependency5: Emacs, Org-mode, Babel language 'shell' enabled
:env_var1: SYNC_ORG_TEMPLATE: holds the full path to this Template.org file
:env_var2: GITHUB_TOKEN: holds the GitHub personal access token
:env_var3: EDITOR: must hold a reference to a working emacsclient server
:env_var4: COLORS
:END:

#+name:Makefile
#+header: :tangle Makefile
#+begin_src makefile

  ###############################################################################
  ### USER-DEPENDENT VARIABLES
  ### USE ENVIRONMENT VARIABLES WHENEVER POSSIBLE

  # NOTE: All environment variables need to be exported PRIOR to starting the
  # Emacs server as EDITOR in your shell startup files; otherwise, they will not
  # be available to Emacs.
  # When I moved from using Bash to Zsh, I inadvertently changed the order of
  # import, and started the Emacs server before importing, and caused a horrible
  # bug which caused the program to work on one computer but fail on another.

  # The absolute path to this Template file
  TEMPLATE := $(SYNC_ORG_TEMPLATE)


  ### TOOLS & RESOURCES
  # tools is a directory holding tangled scripts, such as cmprpl
  # resources is a directory holding static resources for the project
  # images is a directory holding jpg and png image files
  RESOURCES := resources
  TOOLS	    := $(RESOURCES)/tools
  IMAGES    := $(RESOURCES)/images
  CMPRPL    := $(TOOLS)/cmprpl

  # Use emacsclient as $EDITOR; make sure it is set in a shell startup file and
  # the server has been started.
  EMACS	  := $(EMACS)
  EDITOR  := $(EDITOR)

  # User’s personal GitHub token for authentication to GitHub
  # DO NOT HARD-CODE THIS VALUE
  GITHUB_TOKEN := $(GITHUB_TOKEN)

  # The AWS Command Line Interface (AWS CLI) is an open source tool
  # that enables you to interact with AWS services using commands in
  # your command-line shell.  It must be present on your system.  Run the 'make'
  # command 'install-aws-cli' to install it if you do not have it.  Be sure to
  # run 'aws configure' after installing it.  This will place your AWS
  # credentials into ~/.aws/credentials.
  AWS := aws
  S3  := $(AWS) s3
  CFD := $(AWS) cloudfront

  ### END OF USER-DEPENDENT VARIABLES
  ###############################################################################
  ### MAKE-GENERATED VARIABLES

  ### PROJ AND ORG
  # ORG is the name of this Org file with extension .org
  # PROJ is the project name---the Org file name without extension.

  ### NOTE: there can be only one Org file in the project directory;
  # so far this has not been a problem, but it might be.

  PWD  := $(shell pwd)
  ORG  := $(shell ls *.org)
  PROJ := $(basename $(ORG))

  ### NOTE: S is needed only for the Template file because of the way it is nested
  # one level deep in the Templates GitHub repo, which uses the plural form
  # of Templates, whereas this file uses the singular form, Template.  So when
  # the homepage link is updated, the curl command must be told to use the plural
  # form.	 This is obviously a hack only for my own use and can be removed once
  # I clean up this anomaly.

  ifeq ($(PROJ),$(basename $(notdir $(TEMPLATE))))
  S := s
  endif

  # The AWS S3 bucket to use to store the html source file; it is found at the
  # key #+bucket towards the beginning of the file and should include the appropriate
  # suffix (.com, .net, .org, etc)
  BUCKET       := $(shell $(EDITOR) --eval \
		 '(with-current-buffer (find-file-noselect "$(ORG)") \
		    (save-excursion \
		      (goto-char (point-min)) \
		      (re-search-forward "^\#[+]bucket:\\(.*\\)$$" nil t) \
		      (match-string-no-properties 1)))')
  S3_BUCKET    := s3://$(BUCKET)

  # Buckets set up to serve static web sites from S3 can use either http
  # or https protocols; some  http protocols will automatically redirect
  # to https;  however, some only use  http. I would like  to accomodate
  # both, and  so this code  finds the url's  that are in  my Cloudfront
  # account, which presumably will serve https.  If the url is not here,
  # then this must be set up to serve http instead.
  HTTP_S := $(shell $(CFD) list-distributions \
	  | perl -MJSON::PP -e \
		  '$$/=""; \
		   my @urls = (); \
		   my $$json=JSON::PP->new->decode(<STDIN>); \
		   for my $$item ( @{$$json->{"DistributionList"}{"Items"}} ) { \
			  push @urls, @{$$item->{"Aliases"}{"Items"}}; \
		   } \
		  my $$found = grep { /'$(BUCKET)'/ } @urls; \
		  print "http", ($$found ? "s" : "");')

  HTTPS_BUCKET := https://$(BUCKET)

  ### DIR, SRC
  # DIR is the .info name found at '#+texinfo_filename:<DIR>.info' (at
  # the bottom of this file in the export configuration settings)
  # without its extension, used as the INFO filename and the name of the
  # HTML export directory; this code uses the lowercased PROJ name if
  # there is no '#+texinfo_filename'.
  # SRC is HTML directory based upon the DIR name

  #DIR := $(shell $(EDITOR) --eval \
  #	'(with-current-buffer (find-file-noselect "$(ORG)") \
  #		(save-excursion \
  #		(goto-char (point-min)) \
  #		(re-search-forward "^\#[+]\\(?:texinfo_filename\\|TEXINFO_FILENAME\\):\\(.*\\).info$$" nil t) \
  #		(match-string-no-properties 1)))')

  DIR := $(shell sed -E -n "/^\#\+texinfo_filename/s/^.*:(.*)\.info$$/\1/p" $(ORG))
  ifeq ($(DIR),$(EMPTY))
	  DIR := $(shell echo $(PROJ) | tr "[:upper:]" "[:lower:]")
  endif

  SRC := $(DIR)/

  ### VERS: v1.2.34/
  # VERS is the version number of this Org document.
  # When sync is run after the version number has been updated, then VERS
  # picks up the newly-changed value.  VERS used to be staticly imbedded
  # when the Makefile was tangled, but it needs to be dynamic for
  # development.

  # QUERY: should this number be formatted like this, or should it be just the numbers?
  # The reason it includes them is the S3PROJ obtains the name from the S3 bucket, and
  # it includes them.  But it only includes them because I have made it so.  Not a good
  # reason just by itself.  The ending slash is not actually a part of the version, but
  # comes from the way the 'aws2 ls' command returns its values.	So VERS should probably
  # not include the trailing slash, although it doesn’t hurt anything.

  VERS := v$(shell $(EDITOR) --eval \
	  '(with-current-buffer (find-file-noselect "$(ORG)") \
		  (save-excursion \
		    (goto-char (point-min)) \
		    (re-search-forward "^\#[+]\\(?:macro\\|MACRO\\):version Version \\(\\(?:[[:digit:]]+[.]?\\)\\{3\\}\\)") \
		    (match-string-no-properties 1)))')/

  ### AWS
  # PROJ_LIST contains the list of projects currently uploaded to
  # the S3 bucket; each item contains the name of the project and its
  # current version.

  # Created function using elisp instead of the shell.
  # This variable contains an elisp list of strings of the form '("proj1-v1.2.3/" "proj2-v4.5.6/" ...)'
  # However, when it prints to the shell, the quotes are lost.
  # Need to make sure elisp's variable 'exec-path contains the proper $PATH instead of adding to 'exec-path.

  PROJ_LIST := $(shell $(EDITOR) --eval \
	  "(progn \
		  (require (quote seq)) (add-to-list (quote exec-path) (quote \"/usr/local/bin\")) \
		  (seq-map (lambda (s) (replace-regexp-in-string \"^\s+PRE \" \"\" s)) \
			  (seq-filter (lambda (s) (string-match-p (regexp-quote \" PRE \") s)) \
			  (process-lines \"$(AWS)\" \"s3\" \"ls\" \"$(S3_BUCKET)\"))))")

  ### S3PROJ
  # The name of the current project as obtained from S3: 'proj-v1.2.34/'
  # If there is no current project in the S3 bucket, then assign a value equal to
  # the Org project and version instead.  It is set to the project if found, and
  # NO if not found, then updated in the ifeq block below.
  S3PROJ := $(shell $(EDITOR) --eval \
		  '(let ((proj (seq-find (lambda (s) (string-match-p "$(DIR)" s)) (quote $(PROJ_LIST))))) \
		     (or proj (quote NO)))')

  ### PROJINS3
  # is used by make sync; this allows the index.html file to be generated the first
  # time the project is synced.  It is set to NO if this project is not currently in an
  # S3 bucket, and it is set to YES if it is.
  PROJINS3 :=

  ### S3VERS
  # The version of this project currently installed in the S3 bucket: 'v1.2.34/'
  # If there is no current version in the S3 bucket, then assign the version from
  # this Org file instead.
  S3VERS   :=

  # Update S3PROJ, S3VERS, and PROJINS3
  ifeq ($(S3PROJ), NO)
	  S3PROJ := $(DIR)-$(VERS)
	  S3VERS := $(VERS)
	  PROJINS3 := NO
  else
	  S3VERS := $(subst $(DIR)-,,$(S3PROJ))
	  PROJINS3 := YES
  endif

  ### GITHUB
  # USER is the current user's GitHub login name.

  # The user name used to be statically embedded into the Makefile
  # during tangle, but in an effort to make the Makefile dynamically
  # indepedent, dynamic code has replaced the static code.  The code
  # that placed the static name in the Makefile was a 'node' script that
  # ran in a separate Org process during tangle.	An unfortunate fact of
  # 'make' is that 'make' strips the quote marks from the string
  # obtained from the 'curl' command when the 'make shell' command
  # returns the string.	 This makes the string malformed JSON and
  # unparsable by most JSON parsers, including 'node’.	However,
  # 'perl'’s core module JSON::PP (but not JSON::XS) has facilities to
  # parse very malformed JSON strings.	Therefore, this dynamic code
  # uses 'perl' and the core module JSON::PP to parse the 'curl' string
  # into a 'perl' JSON object which can return the login name.	This
  # code should work with any version of 'perl' without having to
  # install any modules.

  USER	:= $(shell \
	    curl -sH "Authorization: token $(GITHUB_TOKEN)" https://api.github.com/user \
	    | \
	    perl -MJSON::PP -e \
		'$$/ = ""; \
		 my $$json = JSON::PP->new->loose->allow_barekey->decode(<STDIN>); \
		 print $$json->{login};' \
	    )
  SAVE		:= resources

  ### TEXINFO
  TEXI		:= $(PROJ).texi
  INFO		:= $(DIR).info
  INFOTN	:= $(shell $(EDITOR) --eval "(file-truename \"$(INFO)\")")
  PDF		:= $(PROJ).pdf
  INDEX		:= index.html
  HTML		:= $(DIR)/$(INDEX)
  DIR_OLD	:= $(DIR)-old

  ### AWS S3
  DST_OLD	:= $(S3_BUCKET)/$(S3PROJ)
  DST_NEW	:= $(S3_BUCKET)/$(DIR)-$(VERS)
  EXCL_INCL	:= --exclude "*" --include "*.html"
  INCL_IMAGES	:= --exclude "*" --include "*.jpg" --include "*.png"
  GRANTS	:= --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers
  S3SYNC	:= $(S3) sync --delete $(EXCL_INCL) $(SRC) $(DST_OLD) $(GRANTS)
  S3MOVE	:= $(S3) mv --recursive $(DST_OLD) $(DST_NEW) $(GRANTS)
  S3COPY	:= $(S3) cp $(INDEX) $(S3_BUCKET) $(GRANTS)
  S3REMOVE	:= $(S3) rm $(S3_BUCKET)/$(S3PROJ) --recursive
  S3IMAGESYNC	:= $(S3) sync $(INCL_IMAGES) $(IMAGES) $(S3_BUCKET)/$(IMAGES) $(GRANTS)

  ###############################################################################

  default: check texi info html pdf

  PHONY: default all check values boot \
	    texi info html pdf \
	    open-org open-texi open-html open-pdf \
	    clean dist-clean wiped-clean \
	    help sync update delete-proj \
	    install-aws-cli \
	    index-html upload-index-html

  values: check
	    @printf "$${BLUE}Values...$${CLEAR}\n"
	    @echo TEMPLATE:	$(TEMPLATE)
	    @echo EDITOR:	$(EDITOR)
	    @echo USER:		$(USER)
	    @echo PWD:		$(PWD)
	    @echo ORG:		$(ORG)
	    @echo TEXI:		$(TEXI)
	    @echo INFO:		$(INFO)
	    @ECHO INFOTN:	$(INFOTN)
	    @echo BUCKET:	$(BUCKET)
	    @echo PROJ:		$(PROJ) $S
	    @echo S3_BUCKET:	$(S3_BUCKET)
	    @echo HTTP_S:	$(HTTP_S)
	    @echo HTTPS_BUCKET:	$(HTTPS_BUCKET)
	    @echo VERS:		$(VERS)
	    @echo S3PROJ:	$(S3PROJ)
	    @echo S3VERS:	$(S3VERS)
	    @echo DIR:		$(DIR)
	    @echo DIR_OLD:	$(DIR_OLD)
	    @echo SRC:		$(SRC)
	    @echo DST_OLD:	$(DST_OLD)
	    @echo DST_NEW:	$(DST_NEW)
	    @echo PROJ_LIST:	"$(PROJ_LIST)"
	    @echo PROJINS3:	$(PROJINS3)

  check:
	    @printf "$${BLUE}Checking dependencies...$${CLEAR}\n"

	    @[[ -z $(BUCKET) ]] && \
	       { printf "$${RED}$(BUCKET) $${CYAN}must be set.$${CLEAR}\n"; exit 1; } || \
	       printf "$${CYAN}BUCKET: $${GREEN}$(BUCKET)$${CLEAR}\n";

	    @[[ -z $${GITHUB_TOKEN} ]] && \
	       { printf "$${RED}GITHUB_TOKEN $${CYAN}must be set.$${CLEAR}\n"; exit 1; } || \
	       printf "$${CYAN}GITHUB_TOKEN: $${GREEN}SET$${CLEAR}\n";

	    @[[ (-d ~/.aws) && (-f ~/.aws/credentials) && (-f ~/.aws/config) ]] && \
	       printf "$${CYAN}AWS credentials and config: $${GREEN}SET$${CLEAR}\n" || \
	       { printf "$${RED}~/.aws 'credentials' and 'config' must be set.$${CLEAR}\n"; exit 1; }

	    @[[ "$(shell $(EDITOR) --eval '(member (quote texinfo) org-export-backends)')" = "(texinfo)" ]] && \
		  printf "$${CYAN}Texinfo backend: $${GREEN}INSTALLED.$${CLEAR}\n" || \
		  { printf "$${YELLOW}Texinfo backend:$${CLEAR} $${RED}NOT INSTALLED; it must be installed.$${CLEAR}\n"; exit 1; }

	    @[[ $(shell $(EDITOR) --eval '(symbol-value org-confirm-babel-evaluate)') == "t" ]] && \
		  { printf "$${YELLOW}org-confirm-babel-evaluate:$${CLEAR} $${RED}T; set to NIL.$${CLEAR}\n"; exit 1; } || \
		  printf "$${CYAN}org-confirm-babel-evaluate: $${GREEN}OFF.$${CLEAR}\n\n"

  open-org: $(ORG)
	    @$(EDITOR) -n $(ORG)
  $(ORG):
	    @echo 'THERE IS NO $(ORG) FILE!!!'
	    exit 1

  texi: $(TEXI)
  $(TEXI): $(ORG)
	   @echo Making TEXI...
	   @$(EDITOR) -u --eval \
		  "(with-current-buffer (find-file-noselect \"$(ORG)\" t) \
			  (save-excursion \
			  (org-texinfo-export-to-texinfo)))"
	   @echo Done making TEXI.
  open-texi: texi
	   @$(EDITOR) -n $(TEXI)

  info: $(INFO)
  $(INFO): $(TEXI)
	   @echo Making INFO...
	   @makeinfo -o $(INFO) $(TEXI)
	   @$(EDITOR) -u -eval \
		  "(when (get-buffer \"$(INFO)\") \
			  (with-current-buffer (get-buffer \"$(INFO)\") \
				  (revert-buffer t t t)))"
	   @echo Done making INFO.

  open-info: info
	   @$(EDITOR) -u -eval \
		  "(if (get-buffer \"*info*\") \
			  (with-current-buffer (get-buffer \"*info*\") \
				(when (not (string= \"(symbol-value (quote Info-current-file))\" \"$(INFOTN)\")) \
					(info \"$(INFOTN)\")) \
				(revert-buffer t t t)) \
		      (info \"$(INFOTN)\"))"

  html: $(HTML)
  $(HTML): $(TEXI)
	   @echo Making HTML INFO..
	   @makeinfo --html -o $(DIR) $(TEXI)
	   @echo Done making HTML.
	   $(CMPRPL) $(DIR) $(DIR_OLD)
  open-html: html
	   @open $(HTML)

  # If pdftexi2dvi produces an error, it may still produce a viable PDF;
  # therefore, use --tidy.  If it produces an error, try to link the PDF;
  # if it does not produce an error, the PDF will be added to the top dir
  # and there will be no attempt to link.
  pdf:	$(PDF)
  $(PDF): $(TEXI)
	  @echo Making PDF INFO...
	  @-pdftexi2dvi --quiet --build=tidy $(TEXI) || ln -s $(PROJ).t2d/pdf/build/$(PDF) $(PDF)
	  @echo Done making PDF.
  open-pdf:pdf
	   @open $(PDF)

  sync:   $(HTML)
	  @echo Syncing version $(VERS) onto $(S3VERS)...
	  $(S3SYNC)
	  $(S3IMAGESYNC)
	  @echo Done syncing.
	  [[ $(VERS) != $(S3VERS) ]] && { echo Moving...; $(S3MOVE); echo Done moving.;  make homepage; } || :
	  [[ $(PROJINS3) = "NO" ]] && make homepage || :

  # This is a target-specific variable for updating the “description”
  # key on the GitHub repo page with the current version number.  It
  # first makes a curl call to the GitHub project repo, finds the
  # “description” line, pulls out the description only (leaving the old
  # version) and then prints the value with the current version number.
  # This value is used by the “homepage:” target in the PATCH call.
  # This method is arguably harder to code but faster to run than using
  # Perl with the JSON::PP module.

  homepage: description = $(shell \
	  curl -s \
		  -H "Authorization: token $(GITHUB_TOKEN)" \
		  https://api.github.com/repos/$(USER)/$(PROJ)$S | \
		  (perl -ne 'if (/^\s*\"description\":\s*\"(.*): v(?:(?:[[:digit:]]+[.]?){3})/) {print $$1}'))

  ### NOTE the use of the S variable at the end of PROJ; this is to handle
  # the singular case of the GitHub repo using the plural form, Templates
  # whereas the the Template.org file uses the singular form.
  homepage: $(ORG) upload-index-html
	    @echo Updating homepage...
	    @echo DESCRIPTION: $(description)
	    @echo VERS: $(VERS)
	    @curl -i \
		  -H "Authorization: token $(GITHUB_TOKEN)" \
		  -H "Content-Type: application/json" \
		  -X PATCH \
		  -d "{\"homepage\":\"$(HTTPS_BUCKET)/$(DIR)-$(VERS)\",\
		       \"description\":\"$(description): $(VERS)\"}" \
		  https://api.github.com/repos/$(USER)/$(PROJ)$S
	    @echo Done updating homepage.

  delete-proj:
	  @echo Deleting project $(PROJ)...
	  @curl -i \
		  -H "Authorization: token $(GITHUB_TOKEN)" \
		  -H "Accept: application/vnd.github.v3+json" \
		  -X DELETE \
		  https://api.github.com/repos/$(USER)/$(PROJ)$S
	  @$(S3REMOVE)
	  @make dist-clean
	  @make upload-index-html
	  @$(EDITOR) -u --eval "(kill-buffer \"$(ORG)\")"
	  @rm -rf "../$(PROJ)"
	  @echo Done deleting project.

  index-html: $(INDEX)
  $(INDEX): $(ORG)
	  @echo making index.html...
	  $(EDITOR) --eval \
	  "(with-current-buffer (find-file-noselect \"$(ORG)\") \
		  (save-excursion \
		    (org-link-search \"#project-index-title\") \
		    (org-export-to-file (quote html) \"index.html\" nil t)))"
	  @echo Done making index.html.

  upload-index-html: $(INDEX)
	   @echo Uploading index.html...
	   $(S3COPY)
	   @echo Done uploading index.html

  install-aws-cli:
	    curl "https://awscli.amazonaws.com/AWSCLIV2.pkg" -o "AWSCLIV2.pkg" && \
	    sudo installer -pkg AWSCLIV2.pkg -target / && \
	    which aws && aws --version
	    rm -rf AWSCLIV2.pkg

  clean:
	  @echo Cleaning...
	    -@rm *~ 2>/dev/null
	    -@for file in *.??*; \
	    do \
		    ext=$${file#$(PROJ).}; \
		    [[ ! $${ext} =~ org|texi|info|pdf|html ]] && rm -rv $${file}; \
	    done

  dist-clean: clean
	  @echo Dist Cleaning...
	    @${EDITOR} -u --eval \
	      "(kill-buffer \"$(ORG)\")"
	    -@rm -rf *.{texi*,info*,html*,pdf*} $(DIR) $(TOOLS)
	    -@for dir in *; \
		do \
		    [ -d $$dir -a $$dir != "$(DIR_OLD)" -a $$dir != $(SAVE) ] && \
		    rm -vr $$dir; \
		done

  wipe-clean: dist-clean
	  @echo Wipe Clean...
	    -@rm -rf Makefile Readme.md $(DIR_OLD)
	    @git checkout Makefile README.md

  git-ready: dist-clean
	    git checkout Makefile
	    git checkout README.md
	    git status

  help:
	    @echo '"make boot" tangles all of the files in Template'
	    @echo '"make default" makes the .texi file, the .info file, \
	    the html files, and the .pdf file.'
	    @echo

	    @echo '"make check" checks for prerequistes'
	    @echo '"make values" runs check and prints variable values'
	    @echo

	    @echo '"make texi" makes the .texi file'
	    @echo '"make info" makes the .info file'
	    @echo '"make html" makes the html distribution in a subdirectory'
	    @echo '"make pdf" makes the .pdf file'
	    @echo

	    @echo '"make open-org" opens the ORG program using emacsclient for editing'
	    @echo '"make open-texi" opens the .texi file using emacsclient for review'
	    @echo '"make open-html" opens the distribution index.html file \
	    in the default web browser'
	    @echo '"make open-pdf" opens the .pdf file'
	    @echo

	    @echo '"make sync" syncs the html files in the AWS S3 bucket BUCKET; \
	    you must have your AWS S3 bucket name in the env var AWS_S3_BUCKET; \
	    You must have your AWS credentials installed in ~/.aws/credentials'
	    @echo

	    @echo '"make install-aws-cli" installs the "aws cli v2" command-line tools'
	    @echo 'You also need to run "aws configure" and supply your Access Key and Secret Access Key'
	    @echo

	    @echo '"make clean" removes the .texi, .info, and backup files ("*~")'
	    @echo '"make dist-clean" cleans, removes the html distribution, \
	    and removes the build directory'
	    @echo '"make wipe-clean" wipes clean the directory, including old directories'
	    @echo

	    @echo '"make delete-proj" deletes the project from the file system, GitHub and AWS'

#+end_src

*** TODO Next
1. The CloudFront configuration needs to be updated recognize the new version
   directory that is created as part of the ~sync~ operation.

2. Update the GitHub HOME website link for each new sync operation.

3. Store on GitHub a version of each other format upon a sync operation (i.e.,
   the INFO and PDF versions)

** Compare Replace

#+begin_comment
The following source code tangles all files during an export operation. This is
to  make  sure  the  ~cmprpl~  source code  exists  in  the  ~resources/tools/~
directory before running  the Makefile target =html=. It also  makes sure there
is a Makefile on an initial export. The following code is not exported.
#+end_comment

#+name:tangle-org-file
#+header: :exports results :eval yes :results silent
#+begin_src emacs-lisp
(org-babel-tangle-file (buffer-file-name))
#+end_src

The  AWS ~sync~  command  relies  upon time  stamps  to  determine whether  two
programs are identical or not, as  well as content.  If two otherwise identical
files have  different time stamps,  ~sync~ will  assume they are  different and
will  process the  newer.   However, the  ~texinfo~  ~makeinfo --html~  command
produces all  new files even  if some files  (or most files)  remain unchanged.
This  means that  all files  will be  uploaded to  the AWS  S3 bucket  on every
iteration, even though the majority of the files are actually unchanged.

The ~cmprpl~  source code attempts to  resolve the issue of  identical exported
code having different  time stamps, thus defeating the benefit  provided by the
~aws2 s3 sync~ command uploading only changed files.

This program makes sure that a generated HTML directory exists: =$DIR_NEW=.  If
it doesn’t, then it is in an improper state and the program stops with an error
message.

The  program then  checks  if  an old  directory  exists,  =$DIR_OLD=.  If  one
doesn’t,  then one  is  created by  copying the  current  new directory.   This
provides a baseline  for comparisons going forward.  The program  exits at that
point. It is very important that  the =$DIR_OLD= directory not be deleted going
forward.

Given  that =$DIR_OLD=  exists, the  program then  loops through  all files  in
=$DIR_NEW= and  compares them  to the  files in =$DIR_OLD=.   If the  files are
identical, the =$DIR_OLD= file replaces the =$DIR_NEW= file while retaining the
old time stamp (using the ~-p~ option of ~cp~. If a file is different, then the
=$DIR_NEW= file  replaces the =$DIR_OLD=  file, thus giving it  updated content
and  an updated  time stamp.   If the  file does  not exist  in the  =$DIR_OLD=
directory, then it is added.

The  program then  loops through  all of  the files  in the  old directory  and
deletes  any that  do not  exist in  the new  directory.  Now  both directories
should be in sync.

#+caption:Compare Replace program
#+name:cmprpl
#+header: :mkdirp t
#+header: :shebang "#!/usr/bin/env bash"
#+begin_src sh :tangle resources/tools/cmprpl
  [[ $# -eq 2 ]] || { echo "ERROR: Incorrect command line arguments"; exit 1; }
  DIR_NEW=$1
  DIR_OLD=$2

  [[ -d $DIR_NEW ]] || { echo "ERROR: $DIR_NEW does not exist"; exit 1; }
  [[ -d $DIR_OLD ]] || { echo "CREATING: $DIR_OLD does not exist"; cp -a $DIR_NEW $DIR_OLD; exit 0; }

  for newfile in $DIR_NEW/*
  do
      oldfile=$DIR_OLD/$(basename $newfile)
      if [[ -e $oldfile ]]
      then
	 if cmp -s $newfile $oldfile
	 then
	     printf "${GREEN}copying OLD to NEW${CLEAR}: "
	     cp -vp $oldfile $newfile
	 else
	     printf "${PURPLE}copying NEW to OLD${CLEAR}: "
	     cp -vp $newfile $oldfile
	 fi
      else
	  printf "${BLUE}creating NEW in OLD${CLEAR}: "
	  cp -vp $newfile $oldfile
      fi
  done

  for oldfile in $DIR_OLD/*
  do
      newfile=$DIR_NEW/$(basename $oldfile)
      if [[ ! -e $newfile ]]
      then
	  printf "${RED}removing OLD${CLEAR}: "
	  rm -v $oldfile
      fi
  done
#+end_src


** Update Utility Commands
*** Get Parsed Org Tree
This function looks for an Org file in the present working directory, and if it
finds one returns  a parsed tree using  ~org-element-parse-buffer~.  It returns
=nil= if there is no Org file or if the found file is not in ~org-mode~.

#+name:get-parsed-org-tree
#+header: :results silent
#+begin_src emacs-lisp
(defun get-parsed-org-tree (&optional org-dir)
  "This function takes an optional directory name, changes to
that directory if given, otherwise uses the pwd, and finds an Org
file and returns its parsed tree, or nil if none found."
  (when org-dir
      (cd (file-name-as-directory org-dir)))
  (let ((buf (car-safe (find-file-noselect "*.org" nil nil t))))
    (if buf
	(with-current-buffer buf (org-element-parse-buffer))
      nil)))
#+end_src

*** Check for CID
This code  checks whether an  Org file contains  a =custom_id= of  a particular
value.  It accepts  a ~cid-value~ and an optional directory.   If the directory
is not given, then it defaults to the current directory.  If throws an error if
the directory does not exist.  It returns =nil= if the given directory does not
contain an Org file.   It returns =t= if the Org file  contains a node property
of   =custom_id=  and   value  ~cid-value~,   or   =nil=  if   not.   It   uses
~get-parsed-org-tree~.

#+name:org-tree-cid-p
#+header: :results silent
#+begin_src emacs-lisp
(defun org-tree-cid-p (cid-value &optional org-dir)
  "Check whether an org file contains a custom_id of CID"
  (let ((tree (get-parsed-org-tree org-dir)))
    (car (org-element-map tree 'property-drawer
	   (lambda (pd) (org-element-map (org-element-contents pd) 'node-property
			  (lambda (np)
			    (and
			     (string= "custom_id" (org-element-property :key np))
			     (string= cid-value (org-element-property :value np))))))
	   nil t))))
#+end_src

#+name:run-org-tree-cid-p
#+header: :var cid="build-tools"
#+header: :var dir="/usr/local/dev/programming/MasteringEmacs"
#+header: :var gpot=get-parsed-org-tree()
#+header: :var otcp=org-tree-cid-p()
#+header: :results value
#+header: :eval never-export
#+begin_src emacs-lisp
(org-tree-cid-p cid dir)
#+end_src

#+call: run-org-tree-cid-p(dir="/usr/local/dev/programming/MasteringEmacs")

** Bucket Index HTML
The bucket should contain a master ~index.html~  file that links to each of the
individual project  ~index.html~ files.  The  master ~index.html~ file  will be
placed at the root of  the bucket, ~https://<bucket-name>.com/~, and the bucket
must be set up to serve this ~index.html~ when the user hits the root.

*** Get Bucket Name
 This  code searches  for  the keyword-value  pair =bucket:<BUCKET-NAME>=  that
 should be  located towards the  beginning of the  file, and returns  the value
 =BUCKET-NAME= or nil if not found.

#+name: get-bucket-name
#+header: :results value
#+begin_src emacs-lisp
   (save-excursion
     (goto-char (point-min))
     (re-search-forward "^#\\+bucket:\\s*?\\(.*\\)$" nil t)
     (match-string-no-properties 1))
#+end_src

For some reason, ~get-bucket-name~ does not  work when called from the headline
[[#project-index-links][=Links for  bucket=]] below  when creating  =index.html=, even  if it  returns as
~(prin1 ...)~ and is  set up to ~:return output~; the  call receives =nil=. The
following code from ~bucket-name~, however, works. I don't know why.

#+name: bucket-name
#+header: :results output
#+header: :var bucket-name=get-bucket-name()
#+begin_src emacs-lisp
(prin1 bucket-name)
#+end_src

*** Bucket HTTPS URL
This  code calls  ~get-bucket-name~ and  returns the  value returned  as a  URL
string or nil.

#+name: bucket-https-url
#+header: :results value
#+header: :var b=get-bucket-name()
#+begin_src emacs-lisp
(concat "https://" b)
#+end_src

*** S3 Bucket URL
This code calls ~get-bucket-name~ and returns the AWS S3 bucket url.

#+name: s3-bucket-url
#+header: :results value
#+header: :var b=get-bucket-name()
#+begin_src emacs-lisp
(concat "s3://" b)
#+end_src

*** Bucket Projects List
This code uses the ~s3-bucket-url~ result to obtain the list of projects in the
bucket.  It does  this by calling the  AWS S3 high-level command  ~ls~ and then
removing the  =PRE= string in  each result.  The result  that is returned  is a
single  string that  can be  separated into  individual links  by breaking  the
string on spaces.

#+name: bucket-projects-list
#+header: :results output
#+header: :var bucket=s3-bucket-url()
#+begin_src sh
/usr/local/bin/aws s3 ls ${bucket} | sed -ne 's/^.*PRE //p'
#+end_src

*** Bucket Project Links
This code  uses the result  from ~bucket-projects-list~ to create  an unordered
list of  links written to  bucket projects, written  in Org-mode syntax.  It is
executed by a =#+call:= in [[*Bucket Index][*Bucket  Index]] during an HTML export of that subtree
to a file called =index.html=.

#+name: bucket-project-links
#+header: :var b-url=bucket-https-url()
#+header: :var projects=bucket-projects-list()
#+header: :results output raw
#+begin_src emacs-lisp
(seq-do (lambda (u) (princ (format "- [[%s/%sindex.html][~%s~]]
" b-url u u))) (split-string projects))
#+end_src

*** Bucket Index
    :PROPERTIES:
    :custom_id: project-index-title
    :export_file_name: index.html
    :export_subtitle: {{{version}}} created {{{upload-date}}}
    :END:
#+html_doctype: html5
#+options: toc:nil html5-fancy:t

#+html: <hr>

**** Links for bucket call_bucket-name()
     :PROPERTIES:
     :unnumbered: t
     :custom_id: project-index-links
     :END:

#+call: bucket-project-links()
** Project Readme
This adds the README.md template to a project. It should be customized uniquely
for the project.

#+name:project-readme
#+header: :tangle README.md
#+begin_src markdown
# TITLE
## Subtitle
## Author
## Date
## Version
# ABSTRACT
This is the Org Template file.	It is the parent of all other Org Info blogs,
and provides the source code for processing them in various different ways.
# INTRODUCTION
# CHAPTER
## Section
### Subsection
#+end_src

** Boot Template
:PROPERTIES:
:dependency1: EMACS:=:/Applications/MacPorts/Emacs.app/Contents/MacOS/Emacs or similar
:dependency2: EDITOR:=:emacsclient
:dependency3: =SYNC_ORG_TEMPLATE= defined as $DEV/Templates/Org/Template.org
:END:
Although running the command ~org-babel-tangle~ (=C-c C-v t=) from within Emacs
will install  everything, it would  be nice to have  a simple Makefile  that is
downloaded with this  file that could be  invoked to do the  same thing without
starting Emacs and Org-mode and keying in the ~org-babel-tangle~ command.  This
little Makefile should be stored on  GitHub along with the ~Template.org~ file.
When  the source  is extracted  to a  directory, then  running this  Makefile's
default rule  as simply ~make~  will extract the ~preprocess.el~  script, which
updates  =DEV= and  then  extracts the  full Makefile.   Because  this file  is
tangled along with the full Makefile, it simply gets tacked onto the end of the
big Makefile as an additional rule.   Now, running ~make~ runs the default rule
from the  main Makefile, which is  to extract everything, then  export to TEXI,
INFO, HTML, and PDF forms.

It is assumed that an Emacs server is running, and that the $EDITOR environment
variable is set to use ~emacsclient~.

#+name:boot-template
#+header: :tangle Makefile
#+begin_src makefile
  boot:
	  $(EDITOR) -u --eval \
		  "(with-current-buffer (car (find-file-noselect \"./*.org\" nil nil t)) \
			  (goto-char (point-min)) \
			  (re-search-forward \"^#[+]name:preprocess.el$$\") \
			  (org-babel-tangle (quote (4))) \
			  (save-buffer) \
			  (kill-buffer))" \
	  --eval \
		  "(let ((rsrcdir \"resources\") \
			 (subdirs (list \"tools\" \"images\"))) \
		     (mkdir rsrcdir t) \
		     (dolist (subdir subdirs) (mkdir (concat rsrcdir \"/\" subdir) t)))"
	  ./resources/tools/preprocess.el
#+end_src

** Preprocess Env Vars
The environment variable DEV can be  in different locations and will be spelled
differently based  on how the  local machine is set  up.  For instance,  on one
system,  it will  be at  ~$HOME/Dev~  while in  another  system it  will be  at
~/usr/local/dev~.  However, the =:tangle= keyword  does not expand variables in
the form ~${DEV}~,  but rather requires absolute  paths, like ~/usr/local/dev~.
Therefore, this program works like a preprocessor for environment variables set
up  as part  of  =:tangle= lines,  changing them  to  their system  environment
variable values prior to tangling.  It lives in the ~resources/tools~ directory.

#+name:preprocess.el
#+header: :mkdirp t
#+header: :tangle resources/tools/preprocess.el
#+header: :shebang "#!/opt/local/bin/emacs -Q --script"
#+begin_src emacs-lisp
  (with-current-buffer (car (find-file-noselect "./*.org" nil nil t))
    (save-excursion
    (goto-char (point-min))
    (let ((re-search-str "\\(?::tangle\\|load-file \\(?:[\\]*\\)?[\"]\\)\s*\\(.*?/[dD]ev\\)/")
          (dev (getenv "DEV")))
      (while
              (re-search-forward re-search-str nil t)
              (replace-match dev t nil nil 1)))
    (save-buffer)
    (require 'org)
    (org-babel-tangle)))
#+end_src

** Samples
#+begin_comment
(cd "~/Dev/Emacs/MasteringEmacs/")
"/Users/pine/Dev/Emacs/MasteringEmacs/"

(defun add-bucket (org bucket)
  "Add a bucket keyword BUCKET to the org file ORG."
  (interactive "fFile: \nsBUCKET: ")
  (with-current-buffer (find-file-noselect org)
    (let* ((tree (org-element-parse-buffer))
	   (ins (car (org-element-map tree (quote section)
		 (lambda (s)
		   (org-element-map s (quote keyword)
		     (lambda (kw) (when (equal "MACRO" (org-element-property :key kw)) (1- (org-element-property :end kw))))
		     nil nil :keyword))
		 nil t nil nil))))
      (goto-char ins)
      (insert (format "#+bucket:%s\n" bucket))
      ())))

(add-bucket "MasteringEmacs.org" "pinecone-forest")
nil

(defun hl-region (raw-hl)
  "Obtain the begin and end positions for a headline."
  (with-current-buffer (find-file-noselect (getenv "SYNC_ORG_TEMPLATE"))
    (let* ((tree (get-parsed-tree))
	   (hl (car-safe (org-element-map tree 'headline
			   (lambda (hl) (when
					    (string= raw-hl
						     (org-element-property :raw-value hl))
					  (org-element-context)))
			   nil nil t))))
      (cons
       (org-element-property :begin hl)
       (org-element-property :end hl))
      )))

(hl-region "Build Tools")

(4888 . 29646)

(defun get-hl-with-prop (org-dir hl-prop)
  "Given a directory containing an Org template file and a custom_id property name, return the headline containing that custom_id, or nil if none."
  (progn
    (cd org-dir)
    (let ((org-buf (car-safe (find-file-noselect "*.org" nil nil t))))
      (if org-buf
	  (with-current-buffer org-buf
	    (let ((tree (org-element-parse-buffer)))
	      (org-element-map tree 'headline
		(lambda (hl)
		  (let ((cid (org-element-property :CUSTOM_ID hl)))
		    (when (string= hl-prop cid)
		      (and
		       (message (format "Found the headline %s containing property %s." (org-element-property :raw-value hl) hl-prop))
		       hl))))
		nil t)))
	(and
	 (message (format "The directory %s does not contain an Org file." org-dir))
	 nil)))))

(get-hl-with-prop "~/Dev/Templates/Org" "build-tools")

(headline (:raw-value "Build Tools" :begin 4888 :end 29646 :pre-blank 0 :contents-begin 4902 :contents-end 29645 :level 1 :priority nil :tags nil :todo-keyword nil :todo-type nil :post-blank 1 :footnote-section-p nil :archivedp nil :commentedp nil :post-affiliated 4888 :FROM-FILE "Template" :CUSTOM_ID "build-tools" :APPENDIX "t" :title "Build Tools"))









;;; Add a keyword named 'bucket' just after the version macro.
;;; This function should be run from within the directory containing the Org file.
(defun add-bucket (org-file s3-bucket)
  "Add the name of the associated AWS S3 bucket to an Org templated file."
  (with-current-buffer (find-file-noselect org-file)
    (goto-char (point-min))
    (let* ((tree (org-element-parse-buffer))
	   ;; find the beginning position of the first headline to act as a limit
	   (hl1 (org-element-map tree (quote headline) (lambda (hl) (org-element-property :begin hl)) nil t)))
      ;; Check for the presence of a bucket keyword before the first headline
      (unless (re-search-forward "^#\\+bucket:" hl1 t)
	;; If no bucket keyword is found, search for a keyword MACRO with the value 'version'
	(org-element-map tree (quote keyword)
	  (lambda (kw) (when (and (string= "MACRO" (org-element-property :key kw))
				  (string-match-p "version" (org-element-property :value kw)))
			 ;; return the end position of the MACRO; subtract an empty line if there is one
			 (goto-char (- (org-element-property :end kw) (org-element-property :post-blank kw)))
			 (insert "#+bucket:" s3-bucket)
			 (newline)
			 (basic-save-buffer)
			 (message (format "Added bucket %s" s3-bucket))))
	  nil t)))))

(add-bucket "MasteringEmacs.org" "pinecone-forest.com")
nil

"Added bucket pinecone-forest.com"









(keyword (:key "MACRO" :value "version Version 0.0.108" :begin 148 :end 181 :post-blank 1 :post-affiliated 148 ...))
("TITLE" "SUBTITLE" "AUTHOR" "DATE" "MACRO" "TEXINFO" "TEXINFO" "CINDEX" "CINDEX" "CINDEX" "CINDEX" "CINDEX" ...)







((keyword (:key "MACRO" :value "version Version 0.0.107" :begin 148 :end 181 :post-blank 1 :post-affiliated 148 ...)))
#+end_comment

* List of Programs
:PROPERTIES:
:appendix: t
:END:
#+texinfo:@listoffloats Listing

* List of Examples
:PROPERTIES:
:appendix: t
:END:
#+texinfo:@listoffloats Example

* Copying
:PROPERTIES:
:copying:  t
:END:

Copyright \copy 2020 by {{{author}}}

* Concept Index
:PROPERTIES:
  :appendix: yes
  :index:    cp
  :END:

* Program Index
:PROPERTIES:
  :appendix: yes
  :index:    pg
  :END:

* Function Index
:PROPERTIES:
  :appendix: yes
  :index:    fn
  :END:

* Variable Index
:PROPERTIES:
  :index: vr
  :appendix: yes
  :END:


* Configuration							   :noexport:
#+startup:content

#+todo: SOMEDAY(s@) TODO(t@) INPROGRESS(i@) WAIT(w@) | CANCEL(c@) DONE(d!)

#+options: H:4

#+texinfo_class: info
#+texinfo_header:
#+texinfo_post_header:
#+texinfo_dir_category:<DIR CATEGORY>
#+texinfo_dir_title:<DIR TITLE>
#+texinfo_dir_desc:<DIR DESCRIPTION>
#+texinfo_printed_title:SSL-TLS---Implementing SSL TLS Using Cryptography and PKI


* Local Variables						   :noexport:
* Footnotes

[fn:1]At the time of this writing, there are only two versions of HTTP; the
differences are immaterial to this book.

[fn:2]In the browser, add =index.text= to the end of the URL to see the source.

[fn:3]Markdown requires the standard Perl library module Digest::MD5.


# Local Variables:
# fill-column: 79
# indent-tabs-mode: t
# eval: (auto-fill-mode)
# time-stamp-pattern: "8/^\\#\\+date:%:y-%02m-%02d %02H:%02M$"
# End:
